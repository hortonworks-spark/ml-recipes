{"paragraphs":[{"text":"%conf\nspark.app.name Spark-ML\nspark.jars /tmp/atlas/spark-atlas-connector-assembly_2.11-0.1.0-SNAPSHOT.jar\nspark.jars.packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0\nspark.extraListeners com.hortonworks.spark.atlas.SparkAtlasEventTracker\nspark.sql.queryExecutionListeners com.hortonworks.spark.atlas.SparkAtlasEventTracker\nspark.sql.streaming.streamingQueryListeners com.hortonworks.spark.atlas.SparkAtlasStreamingQueryEventTracker\n","user":"admin","dateUpdated":"2018-06-21T22:26:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1529020561038_-89670889","id":"20180614-235601_1829676857","dateCreated":"2018-06-14T23:56:01+0000","dateStarted":"2018-06-21T22:26:50+0000","dateFinished":"2018-06-21T22:26:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:754"},{"title":" Step2: Build a Spark ML pipeline and store the trained model into HDFS","text":"%spark2\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.feature.{StopWordsRemover, Tokenizer}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession\nimport spark.implicits._\n\nval training = spark.sql(\"select * from training_table\")\n\ntraining.show()\n\n// Configure an ML pipeline, which consists of three stages: tokenizer, remover.\nval tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n\nval remover = new StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\")\n\nval pipeline = new Pipeline().setStages(Array(tokenizer, remover))\n\nval model = pipeline.fit(training)\n\nval pipelineDir = \"/tmp/pipeline_streaming_dir\"\n\nval modelDir = \"/tmp/model_streaming_dir\"\n\npipeline.write.overwrite().save(pipelineDir)\n\nmodel.write.overwrite().save(modelDir)\n","user":"admin","dateUpdated":"2018-06-21T22:28:02+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true,"fontSize":9},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.feature.{StopWordsRemover, Tokenizer}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession\nimport spark.implicits._\ntraining: org.apache.spark.sql.DataFrame = [text: string]\n+--------------------+\n|                text|\n+--------------------+\n|\"Hortonworks is a...|\n|Temporary views i...|\n|\"Datasets are sim...|\n+--------------------+\n\ntokenizer: org.apache.spark.ml.feature.Tokenizer = tok_01d4ad905c67\nremover: org.apache.spark.ml.feature.StopWordsRemover = stopWords_c83b472c2ee9\npipeline: org.apache.spark.ml.Pipeline = pipeline_b4b3bb3719d6\nmodel: org.apache.spark.ml.PipelineModel = pipeline_b4b3bb3719d6\npipelineDir: String = /tmp/pipeline_streaming_dir\nmodelDir: String = /tmp/model_streaming_dir\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=0","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=1","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=2","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=3","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=4","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=5","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=6","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=7"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1529009689077_1168589782","id":"20180503-200931_1296064876","dateCreated":"2018-06-14T20:54:49+0000","dateStarted":"2018-06-21T22:28:02+0000","dateFinished":"2018-06-21T22:28:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:755"},{"text":"%spark2\n","user":"admin","dateUpdated":"2018-06-14T20:54:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1529009689079_-1579730663","id":"20180506-231703_1473196617","dateCreated":"2018-06-14T20:54:49+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:756"}],"name":"SAC: Spark ML","id":"2DF4E4NE9","noteParams":{},"noteForms":{},"angularObjects":{"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}