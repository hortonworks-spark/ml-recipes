{"paragraphs":[{"text":"%conf\nspark.app.name Spark-Streaming\nspark.jars /tmp/atlas/spark-atlas-connector-assembly_2.11-0.1.0-SNAPSHOT.jar\nspark.jars.packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0\nspark.extraListeners com.hortonworks.spark.atlas.SparkAtlasEventTracker\nspark.sql.queryExecutionListeners com.hortonworks.spark.atlas.SparkAtlasEventTracker\nspark.sql.streaming.streamingQueryListeners com.hortonworks.spark.atlas.SparkAtlasStreamingQueryEventTracker","user":"admin","dateUpdated":"2018-06-21T22:40:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1529020694752_1363032102","id":"20180614-235814_690445349","dateCreated":"2018-06-14T23:58:14+0000","dateStarted":"2018-06-21T22:40:38+0000","dateFinished":"2018-06-21T22:40:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3152"},{"title":"Step3: Build a Spark streaming processing pipeline with trained model for Kafka Streaming","text":"%spark2\n\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.sql.streaming.{OutputMode, Trigger}\n\nval kafkaServer = \"172.27.22.200:6667\"\n\nval sameModel = PipelineModel.load(\"/tmp/model_streaming_dir\")\n \nval df = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", kafkaServer).option(\"subscribe\", \"kafka_input\").load()\n\nval df2 =  df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\").as[(String, String)].toDF(\"id\", \"text\")\n\n//sink streaming data to other kafaka \nval output = sameModel.transform(df2).toDF(\"key\", \"value\", \"words\", \"filtered\").selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n\noutput.writeStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", kafkaServer).option(\"checkpointLocation\", \"/tmp/demo/chckpnt\").option(\"topic\", \"kafka_output\").start()\n","user":"admin","dateUpdated":"2018-06-21T22:40:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true,"fontSize":9},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.sql.streaming.{OutputMode, Trigger}\nkafkaServer: String = 172.27.22.200:6667\nsameModel: org.apache.spark.ml.PipelineModel = pipeline_b4b3bb3719d6\ndf: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\ndf2: org.apache.spark.sql.DataFrame = [id: string, text: string]\noutput: org.apache.spark.sql.DataFrame = [key: string, value: string]\nres5: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@1d5473b0\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=0","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=1","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=2","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=3","http://ctr-e138-1518143905142-364859-01-000004.hwx.site:4041/jobs/job?id=4"],"interpreterSettingId":"spark2"}},"apps":[],"jobName":"paragraph_1529009681224_1846251547","id":"20180503-201028_932250986","dateCreated":"2018-06-14T20:54:41+0000","dateStarted":"2018-06-21T22:40:41+0000","dateFinished":"2018-06-21T22:41:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3153"},{"text":"%spark2\n","user":"admin","dateUpdated":"2018-06-14T20:54:41+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1529009681226_1853252567","id":"20180506-232424_172987971","dateCreated":"2018-06-14T20:54:41+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3154"}],"name":"SAC: Spark Streaming and ML","id":"2DJSKKUA5","noteParams":{},"noteForms":{},"angularObjects":{"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}